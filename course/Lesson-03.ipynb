{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, inputs=[]):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []\n",
    "\n",
    "        for n in self.inputs:\n",
    "            n.outputs.append(self)\n",
    "            # set 'self' node as inbound_nodes's outbound_nodes\n",
    "\n",
    "        self.value = None\n",
    "\n",
    "        self.gradients = {}\n",
    "        # keys are the inputs to this node, and their\n",
    "        # values are the partials of this node with \n",
    "        # respect to that input.\n",
    "        # \\partial{node}{input_i}\n",
    "        \n",
    "\n",
    "    def forward(self):\n",
    "        '''\n",
    "        Forward propagation. \n",
    "        Compute the output value vased on 'inbound_nodes' and store the \n",
    "        result in self.value\n",
    "        '''\n",
    "\n",
    "        raise NotImplemented\n",
    "    \n",
    "\n",
    "    def backward(self):\n",
    "\n",
    "        raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, inputs=[], name=None, is_trainable=True):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []\n",
    "        self.name = name\n",
    "        self.is_trainable = is_trainable\n",
    "        \n",
    "        for n in self.inputs:\n",
    "            n.outputs.append(self)\n",
    "        \n",
    "        self.value = None\n",
    "        \n",
    "        self.gradients = {}\n",
    "        \n",
    "    def forward(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def backward(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Node: {}\".format(self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder is same as tensorflow\n",
    "\n",
    "class Placeholder(Node):\n",
    "    \"\"\"\n",
    "    For x, k, b, weights, bias the value we need to assign value and get the fitted value\n",
    "    \"\"\"\n",
    "    def __init__(self, name, is_trainable=True):\n",
    "        Node.__init__(self, name=name, is_trainable=is_trainable)\n",
    "        \n",
    "    def forward(self, value=None):\n",
    "        if value is not None: self.value = value\n",
    "    \n",
    "    def backward(self):\n",
    "        self.gradients = {}\n",
    "        for n in self.outputs:\n",
    "            self.gradients[self] = n.gradients[self] * 1\n",
    "\n",
    "class Linear(Node):\n",
    "    def __init__(self, x=None, weigth=None, bias=None, name=None, is_trainable=False):\n",
    "        Node.__init__(self, [x, weigth, bias], name=name, is_trainable=is_trainable)\n",
    "        \n",
    "    def forward(self):\n",
    "        k, x, b = self.inputs[1], self.inputs[0], self.inputs[2]\n",
    "        self.value = k.value * x.value + b.value\n",
    "        \n",
    "    def backward(self):\n",
    "        k, x, b = self.inputs[1], self.inputs[0], self.inputs[2]\n",
    "        \n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            \n",
    "            self.gradients[k] = grad_cost * x.value\n",
    "            \n",
    "            self.gradients[x] = grad_cost * k.value\n",
    "            \n",
    "            self.gradients[b] = grad_cost * 1\n",
    "    \n",
    "        \n",
    "class Sigmoid(Node):\n",
    "    def __init__(self, x, name=None, is_trainable=False):\n",
    "        Node.__init__(self, [x], name=name, is_trainable=is_trainable)\n",
    "        self.x = self.inputs[0]\n",
    "        \n",
    "    def _sigmoid(self, x):\n",
    "        return 1. / (1 + np.exp(-1 * x))\n",
    "    \n",
    "    def forward(self):\n",
    "        self.value = self._sigmoid(self.x.value)\n",
    "        \n",
    "    def partial(self):\n",
    "        return self._sigmoid(self.x.value) * (1 - self._sigmoid(self.x.value))\n",
    "    \n",
    "    def backward(self):\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self.x] = grad_cost * self.partial() \n",
    "    #    print(self.gradients)\n",
    "    \n",
    "    \n",
    "class Relu(Node):\n",
    "    def __init__(self, x, name=None, is_trainable=False):\n",
    "        Node.__init__(self, [x], name=name, is_trainable=is_trainable)\n",
    "        self.x = x\n",
    "        \n",
    "    def forward(self):\n",
    "        self.value = self.x.value * (self.x.value > 0)\n",
    "        \n",
    "    def backward(self):\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self.x] = grad_cost * (self.x.value > 0) \n",
    "        \n",
    "\n",
    "class L2_LOSS(Node):\n",
    "    def __init__(self, y, y_hat, name=None, is_trainable=False):\n",
    "        Node.__init__(self, [y, y_hat], name=name, is_trainable=is_trainable)\n",
    "        self.y = y\n",
    "        self.y_hat = y_hat\n",
    "        \n",
    "    def forward(self):        \n",
    "        y_v = np.array(self.y.value)\n",
    "        yhat_v = np.array(self.y_hat.value)\n",
    "        self.value = np.mean((y_v - yhat_v) ** 2)\n",
    "        \n",
    "    def backward(self):\n",
    "        # 1/n sum (y- yhat)**2\n",
    "        y_v = np.array(self.y.value)\n",
    "        yhat_v = np.array(self.y_hat.value)\n",
    "        self.gradients[self.y] = 2 * np.mean((y_v - yhat_v))\n",
    "        self.gradients[self.y_hat] = -2 * np.mean((y_v - yhat_v))\n",
    "     #   print(self.gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toplogic(graph):\n",
    "    sorted_node = []\n",
    "    \n",
    "    while len(graph) > 0: \n",
    "\n",
    "        all_inputs = []\n",
    "        all_outputs = []\n",
    "        \n",
    "        for n in graph:\n",
    "            all_inputs += graph[n]\n",
    "            all_outputs.append(n)\n",
    "        \n",
    "        all_inputs = set(all_inputs)\n",
    "        all_outputs = set(all_outputs)\n",
    "    \n",
    "        need_remove = all_outputs - all_inputs  # which in all_inputs but not in all_outputs\n",
    "    \n",
    "        if len(need_remove) > 0: \n",
    "            node = random.choice(list(need_remove))\n",
    "            \n",
    "            visited_next = [node]\n",
    "            if len(graph) == 1:  visited_next += graph[node]\n",
    "                \n",
    "            graph.pop(node)\n",
    "            sorted_node += visited_next\n",
    "\n",
    "            for _, links in graph.items():\n",
    "                if node in links: links.remove(node)\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    return sorted_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topological_sort_feed_dict(feed_dict):\n",
    "    graph = convert_feed_dict_to_graph(feed_dict)\n",
    "    \n",
    "    return toplogic(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_feed_dict_to_graph(feed_dict):\n",
    "    computing_graph = defaultdict(list)\n",
    "    \n",
    "    nodes = [n for n in feed_dict]\n",
    "    \n",
    "    while nodes:\n",
    "        n = nodes.pop(0) \n",
    "        \n",
    "        if isinstance(n, Placeholder):\n",
    "            n.value = feed_dict[n]\n",
    "        \n",
    "        if n in computing_graph: continue\n",
    "\n",
    "        for m in n.outputs:\n",
    "            computing_graph[n].append(m)\n",
    "            nodes.append(m)\n",
    "    \n",
    "    return computing_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(graph_order, monitor=False):\n",
    "    for node in graph_order:\n",
    "        if monitor: print('forward compuiting -- {}'.format(node))\n",
    "        node.forward()\n",
    "        \n",
    "def backward(graph_order, monitor=False):\n",
    "    for node in graph_order[::-1]:\n",
    "        if monitor: print('backward computing -- {}'.format(node))\n",
    "        node.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_epoch(graph_order, monitor=False):\n",
    "    forward(graph_order, monitor)\n",
    "    backward(graph_order, monitor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(graph, learning_rate=1e-2):\n",
    "    # there are so many other update / optimization methods\n",
    "    # such as Adam, Mom, \n",
    "    for t in graph:\n",
    "        if t.is_trainable:\n",
    "            t.value += -1 * learning_rate * t.gradients[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea6b592a8e643f485fd73b06007c03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = load_boston()\n",
    "X_, y_ = data['data'], data['target']\n",
    "X_rm = X_[:, 5]\n",
    "\n",
    "w1_, b1_ = np.random.normal(), np.random.normal()\n",
    "w2_, b2_ = np.random.normal(), np.random.normal()\n",
    "w3_, b3_ = np.random.normal(), np.random.normal()\n",
    "\n",
    "\n",
    "X, y = Placeholder(name='X', is_trainable=False), Placeholder(name='y', is_trainable=False)\n",
    "w1, b1 = Placeholder(name='w1'), Placeholder(name='b1')\n",
    "w2, b2 = Placeholder(name='w2'), Placeholder(name='b2')\n",
    "\n",
    "# build model\n",
    "output1 = Linear(X, w1, b1, name='linear-01')\n",
    "output2 = Sigmoid(output1, name='activation')\n",
    "#output2 = Relu(output1, name='activation')\n",
    "y_hat = Linear(output2, w2, b2, name='y_hat')\n",
    "cost = L2_LOSS(y, y_hat, name='cost')\n",
    "\n",
    "feed_dict = {\n",
    "    X: X_rm,\n",
    "    y: y_,\n",
    "    w1: w1_,\n",
    "    w2: w2_,\n",
    "    b1: b1_,\n",
    "    b2: b2_,\n",
    "}\n",
    "\n",
    "graph_sort = topological_sort_feed_dict(feed_dict)\n",
    "\n",
    "epoch = 1000\n",
    "\n",
    "batch_num = len(X_rm)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "losses = []\n",
    "\n",
    "for e in tqdm_notebook(range(epoch)):\n",
    "    loss = 0\n",
    "    \n",
    "    for b in range(batch_num):\n",
    "        index = np.random.choice(range(len(X_rm)))\n",
    "        X.value = X_rm[index]\n",
    "        y.value = y_[index]\n",
    "    \n",
    "        run_one_epoch(graph_sort, monitor=False)\n",
    "    \n",
    "        optimize(graph_sort, learning_rate)\n",
    "        \n",
    "        loss += cost.value\n",
    "\n",
    "    losses.append(loss / batch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b1, b2, y, w2, w1, X, linear-01, activation, y_hat, cost]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b516e28fc8>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicate(x, graph):\n",
    "    X.value = x\n",
    "    forward(graph)\n",
    "    return y_hat.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.43200909755811"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicate(7, graph_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1b516ef3c48>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_rm, y_)\n",
    "plt.scatter(X_rm, [predicate(x, graph_sort) for x in X_rm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多维向量版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, inputs=[]):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []\n",
    "\n",
    "        for n in self.inputs:\n",
    "            n.outputs.append(self)\n",
    "            # set 'self' node as inbound_nodes's outbound_nodes\n",
    "\n",
    "        self.value = None\n",
    "\n",
    "        self.gradients = {}\n",
    "        # keys are the inputs to this node, and their\n",
    "        # values are the partials of this node with \n",
    "        # respect to that input.\n",
    "        # \\partial{node}{input_i}\n",
    "        \n",
    "\n",
    "    def forward(self):\n",
    "        '''\n",
    "        Forward propagation. \n",
    "        Compute the output value vased on 'inbound_nodes' and store the \n",
    "        result in self.value\n",
    "        '''\n",
    "\n",
    "        raise NotImplemented\n",
    "    \n",
    "\n",
    "    def backward(self):\n",
    "\n",
    "        raise NotImplemented\n",
    "        \n",
    "class Placeholder(Node):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        An Input node has no inbound nodes.\n",
    "        So no need to pass anything to the Node instantiator.\n",
    "        '''\n",
    "        Node.__init__(self)\n",
    "\n",
    "    def forward(self, value=None):\n",
    "        '''\n",
    "        Only input node is the node where the value may be passed\n",
    "        as an argument to forward().\n",
    "        All other node implementations should get the value of the \n",
    "        previous node from self.inbound_nodes\n",
    "        \n",
    "        Example: \n",
    "        val0: self.inbound_nodes[0].value\n",
    "        '''\n",
    "        if value is not None:\n",
    "            self.value = value\n",
    "            ## It's is input node, when need to forward, this node initiate self's value.\n",
    "\n",
    "        # Input subclass just holds a value, such as a data feature or a model parameter(weight/bias)\n",
    "        \n",
    "    def backward(self):\n",
    "        self.gradients = {self:0}\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self] = grad_cost * 1\n",
    "            \n",
    "        \n",
    "        # input N --> N1, N2\n",
    "        # \\partial L / \\partial N \n",
    "        # ==> \\partial L / \\partial N1 * \\ partial N1 / \\partial N\n",
    "\n",
    "\n",
    "class Add(Node):\n",
    "    def __init__(self, *nodes):\n",
    "        Node.__init__(self, nodes)\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        self.value = sum(map(lambda n: n.value, self.inputs))\n",
    "        ## when execute forward, this node caculate value as defined.\n",
    "\n",
    "class Linear(Node):\n",
    "    def __init__(self, nodes, weights, bias):\n",
    "        Node.__init__(self, [nodes, weights, bias])\n",
    "\n",
    "    def forward(self):\n",
    "        inputs = self.inputs[0].value\n",
    "        weights = self.inputs[1].value\n",
    "        bias = self.inputs[2].value\n",
    "\n",
    "        self.value = np.dot(inputs, weights) + bias\n",
    "        \n",
    "    def backward(self):\n",
    "\n",
    "        # initial a partial for each of the inbound_nodes.\n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            # Get the partial of the cost w.r.t this node.\n",
    "            grad_cost = n.gradients[self]\n",
    "\n",
    "            self.gradients[self.inputs[0]] = np.dot(grad_cost, self.inputs[1].value.T)\n",
    "            self.gradients[self.inputs[1]] = np.dot(self.inputs[0].value.T, grad_cost)\n",
    "            self.gradients[self.inputs[2]] = np.sum(grad_cost, axis=0, keepdims=False)\n",
    "\n",
    "        # WX + B / W ==> X\n",
    "        # WX + B / X ==> W\n",
    "\n",
    "class Sigmoid(Node):\n",
    "    def __init__(self, node):\n",
    "        Node.__init__(self, [node])\n",
    "\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1./(1 + np.exp(-1 * x))\n",
    "\n",
    "    def forward(self):\n",
    "        self.x = self.inputs[0].value\n",
    "        self.value = self._sigmoid(self.x)\n",
    "\n",
    "    def backward(self):\n",
    "        self.partial = self._sigmoid(self.x) * (1 - self._sigmoid(self.x))\n",
    "        \n",
    "        # y = 1 / (1 + e^-x)\n",
    "        # y' = 1 / (1 + e^-x) (1 - 1 / (1 + e^-x))\n",
    "        \n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]  # Get the partial of the cost with respect to this node.\n",
    "\n",
    "            self.gradients[self.inputs[0]] = grad_cost * self.partial\n",
    "            # use * to keep all the dimension same!.\n",
    "\n",
    "\n",
    "\n",
    "class MSE(Node):\n",
    "    def __init__(self, y, a):\n",
    "        Node.__init__(self, [y, a])\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        y = self.inputs[0].value.reshape(-1, 1)\n",
    "        a = self.inputs[1].value.reshape(-1, 1)\n",
    "        assert(y.shape == a.shape)\n",
    "\n",
    "        self.m = self.inputs[0].value.shape[0]\n",
    "        self.diff = y - a\n",
    "\n",
    "        self.value = np.mean(self.diff**2)\n",
    "\n",
    "\n",
    "    def backward(self):\n",
    "        self.gradients[self.inputs[0]] = (2 / self.m) * self.diff\n",
    "        self.gradients[self.inputs[1]] = (-2 / self.m) * self.diff\n",
    "\n",
    "\n",
    "def forward_and_backward(graph):\n",
    "    # execute all the forward method of sorted_nodes.\n",
    "\n",
    "    ## In practice, it's common to feed in mutiple data example in each forward pass rather than just 1. Because the examples can be processed in parallel. The number of examples is called batch size.\n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "        ## each node execute forward, get self.value based on the topological sort result.\n",
    "\n",
    "    for n in  graph[::-1]:\n",
    "        n.backward()\n",
    "\n",
    "###   v -->  a -->  C\n",
    "##    b --> C\n",
    "##    b --> v -- a --> C\n",
    "##    v --> v ---> a -- > C\n",
    "\n",
    "def toplogic(graph):\n",
    "    sorted_node = []\n",
    "    \n",
    "    while len(graph) > 0: \n",
    "\n",
    "        all_inputs = []\n",
    "        all_outputs = []\n",
    "        \n",
    "        for n in graph:\n",
    "            all_inputs += graph[n]\n",
    "            all_outputs.append(n)\n",
    "        \n",
    "        all_inputs = set(all_inputs)\n",
    "        all_outputs = set(all_outputs)\n",
    "    \n",
    "        need_remove = all_outputs - all_inputs  # which in all_inputs but not in all_outputs\n",
    "    \n",
    "        if len(need_remove) > 0: \n",
    "            node = random.choice(list(need_remove))\n",
    "\n",
    "            need_to_visited = [node]\n",
    "\n",
    "            if len(graph) == 1: need_to_visited += graph[node]\n",
    "                \n",
    "            graph.pop(node)\n",
    "            sorted_node += need_to_visited\n",
    "        \n",
    "            for _, links in graph.items():\n",
    "                if node in links: links.remove(node)\n",
    "        else: # have cycle\n",
    "            break\n",
    "        \n",
    "    return sorted_node\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def convert_feed_dict_to_graph(feed_dict):\n",
    "    computing_graph = defaultdict(list)\n",
    "    \n",
    "    nodes = [n for n in feed_dict]\n",
    "    \n",
    "    while nodes:\n",
    "        n = nodes.pop(0) \n",
    "        \n",
    "        if isinstance(n, Placeholder):\n",
    "            n.value = feed_dict[n]\n",
    "        \n",
    "        if n in computing_graph: continue\n",
    "\n",
    "        for m in n.outputs:\n",
    "            computing_graph[n].append(m)\n",
    "            nodes.append(m)\n",
    "    \n",
    "    return computing_graph\n",
    "\n",
    "def topological_sort_feed_dict(feed_dict):\n",
    "    graph = convert_feed_dict_to_graph(feed_dict)\n",
    "    \n",
    "    return toplogic(graph)\n",
    "\n",
    "\n",
    "def optimize(trainables, learning_rate=1e-2):\n",
    "    # there are so many other update / optimization methods\n",
    "    # such as Adam, Mom, \n",
    "    for t in trainables:\n",
    "        t.value += -1 * learning_rate * t.gradients[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples = 506\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle, resample\n",
    "#from miniflow import *\n",
    "\n",
    "# Load data\n",
    "data = load_boston()\n",
    "X_ = data['data']\n",
    "y_ = data['target']\n",
    "\n",
    "# Normalize data\n",
    "X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis=0)\n",
    "\n",
    "n_features = X_.shape[1]\n",
    "n_hidden = 10\n",
    "W1_ = np.random.randn(n_features, n_hidden)\n",
    "b1_ = np.zeros(n_hidden)\n",
    "W2_ = np.random.randn(n_hidden, 1)\n",
    "b2_ = np.zeros(1)\n",
    "\n",
    "# Neural network\n",
    "X, y = Placeholder(), Placeholder()\n",
    "W1, b1 = Placeholder(), Placeholder()\n",
    "W2, b2 = Placeholder(), Placeholder()\n",
    "\n",
    "l1 = Linear(X, W1, b1)\n",
    "s1 = Sigmoid(l1)\n",
    "l2 = Linear(s1, W2, b2)\n",
    "cost = MSE(y, l2)\n",
    "\n",
    "feed_dict = {\n",
    "    X: X_,\n",
    "    y: y_,\n",
    "    W1: W1_,\n",
    "    b1: b1_,\n",
    "    W2: W2_,\n",
    "    b2: b2_\n",
    "}\n",
    "\n",
    "epochs = 5000\n",
    "# Total number of examples\n",
    "m = X_.shape[0]\n",
    "batch_size = 16\n",
    "steps_per_epoch = m // batch_size\n",
    "\n",
    "graph = topological_sort_feed_dict(feed_dict)\n",
    "trainables = [W1, b1, W2, b2]\n",
    "\n",
    "print(\"Total number of examples = {}\".format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 161.970\n",
      "Epoch: 101, Loss: 5.455\n",
      "Epoch: 201, Loss: 4.936\n",
      "Epoch: 301, Loss: 4.343\n",
      "Epoch: 401, Loss: 4.682\n",
      "Epoch: 501, Loss: 4.945\n",
      "Epoch: 601, Loss: 3.676\n",
      "Epoch: 701, Loss: 4.468\n",
      "Epoch: 801, Loss: 3.792\n",
      "Epoch: 901, Loss: 3.802\n",
      "Epoch: 1001, Loss: 3.551\n",
      "Epoch: 1101, Loss: 3.336\n",
      "Epoch: 1201, Loss: 3.592\n",
      "Epoch: 1301, Loss: 3.652\n",
      "Epoch: 1401, Loss: 3.346\n",
      "Epoch: 1501, Loss: 3.479\n",
      "Epoch: 1601, Loss: 2.996\n",
      "Epoch: 1701, Loss: 3.741\n",
      "Epoch: 1801, Loss: 3.230\n",
      "Epoch: 1901, Loss: 3.462\n",
      "Epoch: 2001, Loss: 3.337\n",
      "Epoch: 2101, Loss: 3.093\n",
      "Epoch: 2201, Loss: 3.296\n",
      "Epoch: 2301, Loss: 3.570\n",
      "Epoch: 2401, Loss: 3.253\n",
      "Epoch: 2501, Loss: 3.350\n",
      "Epoch: 2601, Loss: 3.751\n",
      "Epoch: 2701, Loss: 3.022\n",
      "Epoch: 2801, Loss: 2.982\n",
      "Epoch: 2901, Loss: 3.225\n",
      "Epoch: 3001, Loss: 3.414\n",
      "Epoch: 3101, Loss: 3.542\n",
      "Epoch: 3201, Loss: 3.427\n",
      "Epoch: 3301, Loss: 3.179\n",
      "Epoch: 3401, Loss: 3.394\n",
      "Epoch: 3501, Loss: 3.281\n",
      "Epoch: 3601, Loss: 3.268\n",
      "Epoch: 3701, Loss: 2.950\n",
      "Epoch: 3801, Loss: 2.976\n",
      "Epoch: 3901, Loss: 3.339\n",
      "Epoch: 4001, Loss: 3.275\n",
      "Epoch: 4101, Loss: 2.821\n",
      "Epoch: 4201, Loss: 3.057\n",
      "Epoch: 4301, Loss: 3.182\n",
      "Epoch: 4401, Loss: 3.020\n",
      "Epoch: 4501, Loss: 2.920\n",
      "Epoch: 4601, Loss: 3.158\n",
      "Epoch: 4701, Loss: 2.955\n",
      "Epoch: 4801, Loss: 3.236\n",
      "Epoch: 4901, Loss: 3.205\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    for j in range(steps_per_epoch):\n",
    "        # Step 1\n",
    "        # Randomly sample a batch of examples\n",
    "        X_batch, y_batch = resample(X_, y_, n_samples=batch_size)\n",
    "\n",
    "        # Reset value of X and y Inputs\n",
    "        X.value = X_batch\n",
    "        y.value = y_batch\n",
    "\n",
    "        # Step 2\n",
    "        _ = None\n",
    "        forward_and_backward(graph) # set output node not important.\n",
    "\n",
    "        # Step 3\n",
    "        rate = 1e-2\n",
    "    \n",
    "        optimize(trainables, rate)\n",
    "\n",
    "        loss += graph[-1].value\n",
    "    \n",
    "    if i % 100 == 0: \n",
    "        print(\"Epoch: {}, Loss: {:.3f}\".format(i+1, loss/steps_per_epoch))\n",
    "        losses.append(loss/steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Dimensions Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(data['data'])\n",
    "dataframe.columns = data['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = dataframe[['RM', 'LSTAT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-9a2c2ce2f0e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Neural network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPlaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPlaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPlaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPlaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPlaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPlaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'name'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle, resample\n",
    "#from miniflow import *\n",
    "\n",
    "# Load data\n",
    "data = load_boston()\n",
    "X_ = training_data\n",
    "y_ = data['target']\n",
    "\n",
    "# Normalize data\n",
    "X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis=0)\n",
    "\n",
    "n_features = X_.shape[1]\n",
    "n_hidden = 10\n",
    "W1_ = np.random.randn(n_features, n_hidden)\n",
    "b1_ = np.zeros(n_hidden)\n",
    "W2_ = np.random.randn(n_hidden, 1)\n",
    "b2_ = np.zeros(1)\n",
    "\n",
    "# Neural network\n",
    "X, y = Placeholder(), Placeholder()\n",
    "W1, b1 = Placeholder(), Placeholder()\n",
    "W2, b2 = Placeholder(), Placeholder()\n",
    "\n",
    "l1 = Linear(X, W1, b1)\n",
    "s1 = Sigmoid(l1)\n",
    "l2 = Linear(s1, W2, b2)\n",
    "cost = MSE(y, l2)\n",
    "\n",
    "feed_dict = {\n",
    "    X: X_,\n",
    "    y: y_,\n",
    "    W1: W1_,\n",
    "    b1: b1_,\n",
    "    W2: W2_,\n",
    "    b2: b2_\n",
    "}\n",
    "\n",
    "epochs = 200\n",
    "# Total number of examples\n",
    "m = X_.shape[0]\n",
    "batch_size = 1\n",
    "steps_per_epoch = m // batch_size\n",
    "\n",
    "graph = topological_sort_feed_dict(feed_dict)\n",
    "trainables = [W1, b1, W2, b2]\n",
    "\n",
    "print(\"Total number of examples = {}\".format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    for j in range(steps_per_epoch):\n",
    "        # Step 1\n",
    "        # Randomly sample a batch of examples\n",
    "        X_batch, y_batch = resample(X_, y_, n_samples=batch_size)\n",
    "\n",
    "        # Reset value of X and y Inputs\n",
    "        X.value = X_batch\n",
    "        y.value = y_batch\n",
    "\n",
    "        # Step 2\n",
    "    \n",
    "        forward_and_backward(graph) # set output node not important.\n",
    "\n",
    "        # Step 3\n",
    "        rate = 1e-2\n",
    "    \n",
    "        optimize(trainables, rate)\n",
    "\n",
    "        loss += graph[-1].value\n",
    "    \n",
    "    if i % 100 == 0: \n",
    "        print(\"Epoch: {}, Loss: {:.3f}\".format(i+1, loss/steps_per_epoch))\n",
    "        losses.append(loss/steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.value = np.array([[6, 8]])\n",
    "forward_and_backward(graph)\n",
    "graph[-2].value[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = fig.gca(projection='3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Make data.\n",
    "X = X_.values[:, 0]\n",
    "Y = X_.values[:, 1]\n",
    "Z = y_\n",
    "\n",
    "# Plot the surface.\n",
    "rm_and_lstp_price = ax.scatter(X, Y, Z)\n",
    "ax.set_xlabel('RM')\n",
    "ax.set_ylabel('% of lower state')\n",
    "ax.set_zlabel('Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_result = []\n",
    "for rm, ls in training_data.values:\n",
    "    X.value = np.array([[rm, ls]])\n",
    "    forward_and_backward(graph)\n",
    "    predicate_result.append(graph[-2].value[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_result = np.array(predicate_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Make data.\n",
    "X = X_.values[:, 0]\n",
    "Y = X_.values[:, 1]\n",
    "Z = predicate_result\n",
    "\n",
    "# Plot the surface.\n",
    "rm_and_lstp_price = ax.plot_trisurf(X, Y, Z, color='yellow')\n",
    "\n",
    "ax.set_xlabel('RM')\n",
    "ax.set_ylabel('% of lower state')\n",
    "ax.set_zlabel('Predicated-Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
